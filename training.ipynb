{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "root = '/mnt/c/Users/Thanasak/Downloads/archive/'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 4912\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(root + 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get only the first set of pantient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_SET_PANTIENT = 21514\n",
    "\n",
    "def is_patient_id_in_first_set(row):\n",
    "  patient_folder = row['Path'].split('/')[2]\n",
    "  return int(patient_folder.replace('patient', '')) < FIRST_SET_PANTIENT\n",
    "\n",
    "train_csv_set1 = train_csv.copy()\n",
    "train_csv_set1['is_first_set'] = train_csv_set1.apply(is_patient_id_in_first_set, axis=1)\n",
    "train_csv_set1 = train_csv_set1[train_csv_set1['is_first_set'] == True]\n",
    "train_csv_set1.drop(columns=['is_first_set'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_set1['Path'] = train_csv_set1['Path'].str.replace('CheXpert-v1.0-small/', root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get only necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_disease_cols = list(train_csv_set1.columns[:5])\n",
    "interested_disease = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "disease_cols = [col for col in train_csv_set1.columns[5:] if col in interested_disease]\n",
    "train_csv_set1 = train_csv_set1.drop(columns=[col for col in train_csv_set1.columns if col not in non_disease_cols + disease_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace -1.0 with 1.0 (U-One) and Nan with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_set1[disease_cols] = train_csv_set1[disease_cols].fillna(0.0).replace(-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### drop images don't have balance ratio (width and height differ than 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def width_height_difference(image_path):\n",
    "  img = Image.open(image_path)\n",
    "  width, height = img.size\n",
    "  return abs(width - height), width, height\n",
    "\n",
    "weird_ratio_image = []\n",
    "\n",
    "for index, row in train_csv_set1.iterrows():\n",
    "  diff, width, height = width_height_difference(row['Path'])\n",
    "  if diff > 200:\n",
    "    diseases = [row[disease] for disease in interested_disease]\n",
    "    weird_ratio_image.append((row['Path'], width, height, diff, max(width / height, height / width), *diseases))\n",
    "\n",
    "dropping_image = pd.DataFrame(weird_ratio_image, columns=['Path', 'Width', 'Height', 'Difference', 'Ratio'] + interested_disease)\n",
    "print(dropping_image)\n",
    "\n",
    "image_diff_paths = dropping_image['Path'].tolist()\n",
    "train_csv_set1 = train_csv_set1[~train_csv_set1['Path'].isin(image_diff_paths)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save clean csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_set1.to_csv('train_set1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "train_csv_set1 = pd.read_csv('train_set1.csv')\n",
    "valid_csv = pd.read_csv(root + 'valid.csv')\n",
    "valid_csv['Path'] = valid_csv['Path'].str.replace('CheXpert-v1.0-small/', root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 3\n",
    "num_rows = (len(disease_cols) + num_cols - 1) // num_cols  \n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(disease_cols):\n",
    "    value_counts = train_csv_set1[col].value_counts(dropna=False)\n",
    "    value_counts = value_counts.reindex([np.nan, -1.0, 0.0, 1.0])\n",
    "\n",
    "    value_counts.plot(kind='bar', ax=axes[i], color='b', alpha=0.7)\n",
    "    \n",
    "    axes[i].set_title(f\"Value counts for {col}\")\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "for j in range(i+1, num_rows * num_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_grid_tensor(images, title):\n",
    "  grid_size = int(math.ceil(math.sqrt(images.shape[0])))\n",
    "  plt.figure(figsize=(grid_size * 2, grid_size * 2))\n",
    "  for i, image in enumerate(images):\n",
    "    plt.subplot(grid_size, grid_size, i + 1)\n",
    "    image = image.permute(1, 2, 0)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "  plt.suptitle(title, fontsize=16)\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, data, disease_list, transforms):\n",
    "    self.data = data\n",
    "    self.disease_list = disease_list\n",
    "    self.transforms = transforms\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.data.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    data = self.data.iloc[idx]\n",
    "    image = cv2.imread(data[\"Path\"])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = self.transforms(image)\n",
    "    labels = data[self.disease_list].values.astype(float)\n",
    "    angle = data[\"Frontal/Lateral\"]\n",
    "\n",
    "    return image, labels, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "  def __init__(self, model, target_layers):\n",
    "    self.model = model\n",
    "    self.target_layers = target_layers\n",
    "    self.gradients = {}\n",
    "    self.activations = {}\n",
    "\n",
    "    self._register_hooks()\n",
    "\n",
    "  def _register_hooks(self):\n",
    "    def forward_hook(module, input, output, layer_name):\n",
    "      self.activations[layer_name] = output\n",
    "    def backward_hook(module, grad_input, grad_output, layer_name):\n",
    "      self.gradients[layer_name] = grad_output[0]\n",
    "\n",
    "    for name, module in self.model.named_modules():\n",
    "      if name in self.target_layers:\n",
    "        module.register_forward_hook(lambda mod, inp, out, name=name: forward_hook(mod, inp, out, name))\n",
    "        module.register_backward_hook(lambda mod, grad_inp, grad_out, name=name: backward_hook(mod, grad_inp, grad_out, name))\n",
    "\n",
    "  def generate_cam(self, input_image, class_idx=None):\n",
    "    output = self.model(input_image)\n",
    "    if class_idx is None:\n",
    "      class_idx = torch.argmax(output)\n",
    "\n",
    "    self.model.zero_grad()\n",
    "    target = output[0, class_idx]\n",
    "    target.backward()\n",
    "\n",
    "    cams = {}\n",
    "\n",
    "    for layer in self.target_layers:\n",
    "      gradients = self.gradients[layer][0].cpu().detach().numpy()\n",
    "      activations = self.activations[layer][0].cpu().detach().numpy()\n",
    "\n",
    "      weights = np.mean(gradients, axis=(1, 2))\n",
    "\n",
    "      cam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
    "      for i, w in enumerate(weights):\n",
    "        cam += w * activations[i]\n",
    "\n",
    "      cam = np.maximum(cam, 0)\n",
    "\n",
    "      cam = cam - np.min(cam)\n",
    "      cam = cam / np.max(cam)\n",
    "      cam = cv2.resize(cam, (input_image.shape[2], input_image.shape[3]))\n",
    "      cams[layer] = cam\n",
    "\n",
    "    return cams\n",
    "\n",
    "  def visualize(self, input_image_path, cams, output_path):\n",
    "    img = Image.open(input_image_path).convert('RGB')\n",
    "\n",
    "    preprocess = transforms.Compose([transforms.Resize(320), transforms.CenterCrop(320)])\n",
    "    img = preprocess(img)\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img = np.float32(img) / 255\n",
    "\n",
    "    for layer in self.target_layers:\n",
    "      heatmap = cv2.applyColorMap(np.uint8(255 * cams[layer]), cv2.COLORMAP_JET)\n",
    "      heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "      superimposed_img = heatmap + img\n",
    "      superimposed_img = superimposed_img / np.max(superimposed_img)\n",
    "\n",
    "      plt.imshow(superimposed_img)\n",
    "      plt.axis('off')\n",
    "      plt.savefig(f\"{output_path}/{layer}.jpg\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(tensor):\n",
    "  return (tensor - tensor.min()) / (tensor.max() - tensor.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tranform with mean and std of ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Resize(320, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "  transforms.CenterCrop(320),\n",
    "  transforms.Lambda(lambda image: min_max_norm(image)),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data=train_csv_set1, disease_list=disease_cols, transforms=transform)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=16, num_workers=8, prefetch_factor=4, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, angles = next(iter(dataloader))\n",
    "imshow_grid_tensor(images, 'test first batch')\n",
    "print(images.shape)\n",
    "print(labels)\n",
    "print(angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(nn.Module):\n",
    "  def __init__(self, num_classes=5):\n",
    "    super(CustomDenseNet, self).__init__()\n",
    "    self.net = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "\n",
    "    for param in self.net.features.parameters():\n",
    "      param.requires_grad = False\n",
    "    \n",
    "    for param in self.net.classifier.parameters():\n",
    "      param.requires_grad = True\n",
    "\n",
    "    self.net.classifier = nn.Linear(in_features=self.net.classifier.in_features, out_features=num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.net(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = CustomDenseNet()\n",
    "densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "  def __init__(self, num_classes=5):\n",
    "    super(CustomResNet, self).__init__()\n",
    "    self.net = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    for param in self.net.parameters():\n",
    "      param.requires_grad = False\n",
    "    \n",
    "    for param in self.net.fc.parameters():\n",
    "      param.requires_grad = True\n",
    "\n",
    "    self.net.fc = nn.Linear(in_features=self.net.fc.in_features, out_features=num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.net(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = CustomResNet()\n",
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Focal Loss with Weighted image angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossWithAngle(nn.Module):\n",
    "  def __init__(self, alpha=.25, gamma=2, angle_weights=None, reduction='mean'):\n",
    "    super(FocalLossWithAngle, self).__init__()\n",
    "    self.alpha = alpha\n",
    "    self.gamma = gamma\n",
    "    self.reduction = reduction\n",
    "    self.angle_weights = angle_weights\n",
    "\n",
    "  def forward(self, inputs, targets, angle):\n",
    "    loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "    pt = torch.exp(loss)\n",
    "    focal_loss = self.alpha * (1 - pt) ** self.gamma * loss\n",
    "\n",
    "    for i, a in enumerate(angle):\n",
    "      angle_weight = self.angle_weights[a] if self.angle_weights else 1.0\n",
    "      focal_loss[i] *= angle_weight\n",
    "\n",
    "    if self.reduction == 'mean':\n",
    "      return focal_loss.mean()\n",
    "    else:\n",
    "      return focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, train_loader, val_loader, epochs=10, checkpoint_path=None, device='cpu'):\n",
    "  model = model.to(device)\n",
    "  scaler = GradScaler()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "\n",
    "    avg_train_loss = 0.0\n",
    "    avg_test_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader, desc=f'🚀Training Epoch [{epoch+1}/{epochs}]', unit='batch')\n",
    "    for images, labels, angles in train_bar:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      opt.zero_grad()\n",
    "\n",
    "      with autocast():\n",
    "        outputs = model(images)\n",
    "        train_loss = loss_fn(outputs, labels, angles)\n",
    "\n",
    "      scaler.scale(train_loss).backward()\n",
    "      scaler.step(opt)\n",
    "      scaler.update()\n",
    "\n",
    "      avg_train_loss += train_loss.item()\n",
    "      train_bar.set_postfix(train_loss=train_loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    test_bar = tqdm(val_loader, desc='📄Testing', unit='batch')\n",
    "    for images, labels, angles in test_bar:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      with autocast():\n",
    "        outputs = model(images)\n",
    "        test_loss = loss_fn(outputs, labels, angles)\n",
    "\n",
    "      avg_test_loss += test_loss.item()\n",
    "\n",
    "      test_bar.set_postfix(test_loss=test_loss.item())\n",
    "    \n",
    "    avg_train_loss /= len(train_loader)\n",
    "    avg_test_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Loss epoch: {epoch + 1}\")\n",
    "    print(f\"Train Loss {avg_train_loss}\")\n",
    "    print(f\"Test Loss {avg_test_loss}\")\n",
    "\n",
    "    if checkpoint_path is not None:\n",
    "      torch.save(model.state_dict(), checkpoint_path + f'-{epoch + 1}.pth')\n",
    "      print(f\"Model saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = FocalLossWithAngle(angle_weights={\"Frontal\": 1.0, \"Lateral\": 2.0})\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "\n",
    "train_dataset = CustomDataset(data=train_csv_set1, disease_list=disease_cols, transforms=transform)\n",
    "valid_dataset = CustomDataset(data=valid_csv, disease_list=disease_cols, transforms=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, num_workers=8, prefetch_factor=4, pin_memory=True, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=train_dataset, batch_size=16, num_workers=8, prefetch_factor=4, pin_memory=True, shuffle=True)\n",
    "\n",
    "train(\n",
    "  model=resnet,\n",
    "  opt=optimizer,  \n",
    "  loss_fn=loss_fn,\n",
    "  train_loader=train_loader,\n",
    "  val_loader=valid_loader,\n",
    "  epochs=10,\n",
    "  checkpoint_path='checkpoint/resnet-ver1',\n",
    "  device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet.load_state_dict(torch.load('checkpoints/densenet-ver1-10.pth', weights_only=True))\n",
    "resnet.load_state_dict(torch.load('checkpoints/resnet-ver1-10.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_cols = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "test_csv = pd.read_csv('test_labels.csv')\n",
    "\n",
    "def get_view_type(path):\n",
    "  if 'frontal' in path.lower():\n",
    "    return 'Frontal'\n",
    "  elif 'lateral' in path.lower():\n",
    "    return 'Lateral'\n",
    "  else:\n",
    "    return 'Unknown'\n",
    "\n",
    "test_csv['Frontal/Lateral'] = test_csv['Path'].apply(get_view_type)\n",
    "\n",
    "test_set = CustomDataset(data=test_csv, disease_list=disease_cols, transforms=transform)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=16, num_workers=8, prefetch_factor=4, pin_memory=True, shuffle=True)\n",
    "loss_fn = FocalLossWithAngle(angle_weights={\"Frontal\": 1.0, \"Lateral\": 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try to plot test set labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 3\n",
    "num_rows = (len(disease_cols) + num_cols - 1) // num_cols  \n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10)) \n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(disease_cols):\n",
    "  value_counts = test_csv[col].value_counts(dropna=False)\n",
    "  value_counts = value_counts.reindex([np.nan, -1.0, 0.0, 1.0])\n",
    "\n",
    "  value_counts.plot(kind='bar', ax=axes[i], color='b', alpha=0.7)\n",
    "  \n",
    "  axes[i].set_title(f\"Value counts for {col}\")\n",
    "  axes[i].set_ylabel('Count')\n",
    "\n",
    "for j in range(i+1, num_rows * num_cols):\n",
    "  fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(outputs, labels, disease_classes=['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']):\n",
    "  preds = (torch.sigmoid(torch.from_numpy(outputs)).numpy() > 0.5)\n",
    "\n",
    "  if len(labels.shape) == 1:\n",
    "    labels = labels.reshape(-1, len(disease_classes))\n",
    "  if len(preds.shape) == 1:\n",
    "    preds = preds.reshape(-1, len(disease_classes))\n",
    "\n",
    "  num_classes = labels.shape[1]\n",
    "  \n",
    "  for i in range(num_classes):\n",
    "    precision = precision_score(labels[:, i], preds[:, i], zero_division=1)\n",
    "    recall = recall_score(labels[:, i], preds[:, i], zero_division=1)\n",
    "    f1 = f1_score(labels[:, i], preds[:, i], zero_division=1)\n",
    "\n",
    "    print(f\"{disease_classes[i]} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    cm = confusion_matrix(labels[:, i], preds[:, i])\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f\"Confusion Matrix for {disease_classes[i]}\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correct_incorrect(correct_samples, incorrect_samples, title, n_samples=6):\n",
    "\n",
    "  plt.figure(figsize=(8, 4))\n",
    "  plt.suptitle(title, fontsize=16)\n",
    "\n",
    "  correct_samples = correct_samples[:n_samples]\n",
    "  incorrect_samples = incorrect_samples[:n_samples]\n",
    "\n",
    "  for idx, img in enumerate(correct_samples):\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.subplot(2, n_samples, idx + 1)\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.title('Correct')\n",
    "    plt.axis('off')\n",
    "\n",
    "  for idx, img in enumerate(incorrect_samples):\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.subplot(2, n_samples, n_samples + idx + 1)\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.title('Incorrect')\n",
    "    plt.axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_classes = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "correct_images_per_class = {class_name: [] for class_name in disease_classes}\n",
    "incorrect_images_per_class = {class_name: [] for class_name in disease_classes}\n",
    "\n",
    "densenet.eval()\n",
    "densenet.to(device)\n",
    "avg_loss = 0.0\n",
    "correct_preds = 0\n",
    "total_samples = 0\n",
    "output_list = []\n",
    "label_list = []\n",
    "for images, labels, angles in test_loader:\n",
    "  images, labels = images.to(device), labels.to(device)\n",
    "  outputs = densenet(images)\n",
    "  loss = loss_fn(outputs, labels, angles)\n",
    "  avg_loss += loss.item()\n",
    "\n",
    "  preds = (torch.sigmoid(outputs).cpu().detach().numpy() > 0.5)\n",
    "  \n",
    "  correct_preds += (preds == labels.cpu().detach().numpy()).sum()\n",
    "  total_samples += labels.size(0) * labels.size(1)\n",
    "\n",
    "  output_list.extend(outputs.cpu().detach().numpy())\n",
    "  label_list.extend(labels.cpu().detach().numpy())\n",
    "  \n",
    "  for i in range(len(preds)):\n",
    "    for class_idx, class_name in enumerate(disease_classes):\n",
    "      if preds[i][class_idx] == labels[i][class_idx].cpu().numpy():\n",
    "        if len(correct_images_per_class[class_name]) < 6:\n",
    "          correct_images_per_class[class_name].append(images[i].cpu().numpy())\n",
    "        else:\n",
    "          if len(incorrect_images_per_class[class_name]) < 6:\n",
    "            incorrect_images_per_class[class_name].append(images[i].cpu().numpy())\n",
    "\n",
    "print(\"Test Loss:\", avg_loss / len(test_loader))\n",
    "print(\"Accuracy:\", correct_preds / total_samples)\n",
    "\n",
    "all_outputs = np.concatenate(output_list, axis=0)\n",
    "all_labels = np.concatenate(label_list, axis=0)\n",
    "\n",
    "print()\n",
    "plot_confusion_matrices(all_outputs, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot samples of correct and incorrect predict in each classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in disease_classes:\n",
    "  plot_correct_incorrect(correct_images_per_class[class_name], incorrect_images_per_class[class_name], f\"sample of {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_classes = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "correct_images_per_class = {class_name: [] for class_name in disease_classes}\n",
    "incorrect_images_per_class = {class_name: [] for class_name in disease_classes}\n",
    "\n",
    "resnet.eval()\n",
    "resnet.to(device)\n",
    "avg_loss = 0.0\n",
    "correct_preds = 0\n",
    "total_samples = 0\n",
    "output_list = []\n",
    "label_list = []\n",
    "for images, labels, angles in test_loader:\n",
    "  images, labels = images.to(device), labels.to(device)\n",
    "  outputs = resnet(images)\n",
    "  loss = loss_fn(outputs, labels, angles)\n",
    "  avg_loss += loss.item()\n",
    "\n",
    "  preds = (torch.sigmoid(outputs).cpu().detach().numpy() > 0.5)\n",
    "  \n",
    "  correct_preds += (preds == labels.cpu().detach().numpy()).sum()\n",
    "  total_samples += labels.size(0) * labels.size(1)\n",
    "\n",
    "  output_list.extend(outputs.cpu().detach().numpy())\n",
    "  label_list.extend(labels.cpu().detach().numpy())\n",
    "  \n",
    "  for i in range(len(preds)):\n",
    "    for class_idx, class_name in enumerate(disease_classes):\n",
    "      if preds[i][class_idx] == labels[i][class_idx].cpu().numpy():\n",
    "        if len(correct_images_per_class[class_name]) < 6:\n",
    "          correct_images_per_class[class_name].append(images[i].cpu().numpy())\n",
    "        else:\n",
    "          if len(incorrect_images_per_class[class_name]) < 6:\n",
    "            incorrect_images_per_class[class_name].append(images[i].cpu().numpy())\n",
    "\n",
    "print(\"Test Loss:\", avg_loss / len(test_loader))\n",
    "print(\"Accuracy:\", correct_preds / total_samples)\n",
    "\n",
    "all_outputs = np.concatenate(output_list, axis=0)\n",
    "all_labels = np.concatenate(label_list, axis=0)\n",
    "\n",
    "print()\n",
    "plot_confusion_matrices(all_outputs, all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in disease_classes:\n",
    "  plot_correct_incorrect(correct_images_per_class[class_name], incorrect_images_per_class[class_name], f\"sample of {class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "densenet.eval()\n",
    "resnet.eval()\n",
    "images, labels, angles = next(iter(test_loader))\n",
    "test_input = images[0].to(device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "densenet(test_input)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Inference time: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "resnet(test_input)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Inference time: {elapsed_time:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
